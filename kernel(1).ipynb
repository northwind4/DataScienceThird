{
  "cells": [
    {
      "metadata": {
        "_uuid": "c79a15c1c16c7e996ab35fb7925633f59ab90b2a"
      },
      "cell_type": "markdown",
      "source": "Hello.\nI have changed the dataset because of the old dataset(World Happiness Report) had no value 'NaN'.\n\nThis homerwork kernel is about these issues :\n* Diagnose data for cleaning\n* Explotanory data analysis \n* Visual explotanory data analysis\n* Tidy Data\n* Pivoting Data\n* Concatenating Dataframes\n* DataTypes\n* Missing Data and Test with Asserts\n"
    },
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "data = pd.read_csv('../input/anime.csv')\ndata.info()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "6960163e6a50a13e8525c5ba663c5d55435f0f3e"
      },
      "cell_type": "markdown",
      "source": "Lets check frequency value of the 'Type ' column."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1dbc7bbf6184c7c10b0f6c610be0f6030aed1d77",
        "scrolled": true
      },
      "cell_type": "code",
      "source": "print(data['type'].value_counts(dropna=True))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "952d5808676ca29c99dd41120dde9383f8b13687"
      },
      "cell_type": "markdown",
      "source": "### EXPLORATORY DATA ANALYSIS\n\n\n<br>outliers: the value that is considerably higher or lower from rest of the data\n* Lets say value at 75% is Q3 and value at 25% is Q1. \n* Outlier are smaller than Q1 - 1.5(Q3-Q1) and bigger than Q3 + 1.5(Q3-Q1). (Q3-Q1) = IQR\n<br>We will use describe() method. Describe method includes:\n* count: number of entries\n* mean: average of entries\n* std: standart deviation\n* min: minimum entry\n* 25%: first quantile\n* 50%: median or second quantile\n* 75%: third quantile\n* max: maximum entry\n\n<br> What is quantile?\n\n* 1,4,5,6,8,9,11,12,13,14,15,16,17\n* The median is the number that is in **middle** of the sequence. In this case it would be 11.\n\n* The lower quartile is the median in between the smallest number and the median i.e. in between 1 and 11, which is 6.\n* The upper quartile, you find the median between the median and the largest number i.e. between 11 and 17, which will be 14 according to the question above."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4b808491171fab7cd3e8d8e9ead1fd21146de727"
      },
      "cell_type": "code",
      "source": "data.describe()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "0d09f04ec9b7b27c70f0cc941a43365b20829773"
      },
      "cell_type": "markdown",
      "source": "### VISUAL EXPLORATORY DATA ANALYSIS\n* Box plots: visualize basic statistics like outliers, min/max or quantiles"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e427178d4f496602f45f543914eaccfbe507df93"
      },
      "cell_type": "code",
      "source": "data.boxplot(column = 'rating', by='type', figsize = (13,13))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "a1d0b21d1276eff71ad0ef8d671f3763f46a866f"
      },
      "cell_type": "markdown",
      "source": "### Melting & Pivoting Dataset\n\nWhen we would see especially the result of relation between different columns, we using melting function.\nPivoting function is reverse of melting.****"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0b453083747e46427f4636e445851980e664717e",
        "scrolled": true
      },
      "cell_type": "code",
      "source": "#id_vars is what we don't want to wish to melt\n#value_vars is what we want to wish to melt\ndata_new = data.head()\nmelted = pd.melt(frame=data_new, id_vars = 'name', value_vars =['genre', 'type'])\nmelted",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f7e9c133d34ea77b5107506b2caf1ac77abfa9e9"
      },
      "cell_type": "code",
      "source": "melted.pivot(index = 'name', columns = 'variable', values = 'value')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "b825d021427d8cc93e8e5b40fa318881159455ca"
      },
      "cell_type": "markdown",
      "source": "### Concatenating Dataframes\nWe will concatenate two dataframes. We will do it from two different ways : \n* Vertical concatenate\n* Horizontal concatenate"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "85c37764f6b3a65cb5623eb0b2974eda2ee332ad"
      },
      "cell_type": "code",
      "source": "data1 = data.head()\ndata2 = data.tail()\nconc_data_row = pd.concat([data1,data2], axis = 0, ignore_index=True)#axis=0 is meaning, vertical concat.\nconc_data_row",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "889c5555766bd6722a01ab0d4067903bf8f0a5a7"
      },
      "cell_type": "code",
      "source": "data_conc_cols = pd.concat([data1,data2], axis = 1 , ignore_index=True)#axis = 1 is meaning, horizontal cocnat.\ndata_conc_cols",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "c120040a7b3f62f2f7eb1e422ad83585ca0e750e"
      },
      "cell_type": "markdown",
      "source": "### Data Types \n\nThere are 5 basic data types: object(string),booleab,  integer, float and categorical.\n<br> We can make conversion data types like from str to categorical or from int to float\n<br> Why is category important: \n* make dataframe smaller in memory \n* can be utilized for anlaysis especially for sklear(we will learn later)"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "15ef9b4a431376a51f4c57e0e023f00794331a7f"
      },
      "cell_type": "code",
      "source": "data.dtypes",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "00985865020649b0ce7cc7d5319fbf826a6485e6"
      },
      "cell_type": "code",
      "source": "data['type'] = data['type'].astype('category')\ndata['anime_id'] = data['anime_id'].astype('float')\ndata.dtypes",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "9b1a8a13ce68f115401d5b542b3d996c08a17cda"
      },
      "cell_type": "markdown",
      "source": "<a id=\"24\"></a> <br>\n### MISSING DATA and TESTING WITH ASSERT\nIf we encounter with missing data, what we can do:\n* leave as is\n* drop them with dropna()\n* fill missing value with fillna()\n* fill missing values with test statistics like mean\n<br>Assert statement: check that you can turn on or turn off when you are done with your testing of the program"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1c5cc0fc93e56e2fdc66a6b9f074dfebf81969d4"
      },
      "cell_type": "code",
      "source": "data.info()\n#there are 12294 object in out dataframe.\n#but as we can see, there are 12064 rating value at dataframe",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "956c0156ea72f5655fea242aa2a20661066f6f43"
      },
      "cell_type": "code",
      "source": "data['rating'].value_counts(dropna=False)\n#there are 230 NaN value.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "282bf3c051bc8e74e78d5d57524bfb80d6044051"
      },
      "cell_type": "code",
      "source": "dataNew = data\ndataNew['rating'].dropna(inplace =True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "cfe1eef5c112d6bf2012094f4f9f66a63bce7e74"
      },
      "cell_type": "markdown",
      "source": "### How can we use ' Assert ' ?\nAssert statement works like ' if statement. If assert gets boolean 1, returns nothing. But if assert gets boolean 0, returns error."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9e7b440196d5af3f86b280fff1dfd231efaa3afd"
      },
      "cell_type": "code",
      "source": "assert 1 == 1 # returns nothing.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b50bc6e277ca19e0577de9e3d1d69b1dc1c52ddc"
      },
      "cell_type": "code",
      "source": "assert 1 == 2 # returns error.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3a5c454a0ddea3e66396383abe5ab80e31fcaf16"
      },
      "cell_type": "code",
      "source": "assert dataNew['rating'].dropna().all()#returns nothing because of we dropped all NaN values already.",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}